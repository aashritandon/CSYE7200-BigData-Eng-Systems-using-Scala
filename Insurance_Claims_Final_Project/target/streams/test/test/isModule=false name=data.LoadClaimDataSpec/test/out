[0m[[0minfo[0m] [0m[32mLoadClaimDataSpec:[0m[0m
[0m[[0minfo[0m] [0m[31mException encountered when attempting to run a suite with class name: data.LoadClaimDataSpec *** ABORTED ***[0m[0m
[0m[[0minfo[0m] [0m[31m  java.lang.IllegalArgumentException: There is already an RpcEndpoint called LocalBackendEndpoint[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.rpc.netty.Dispatcher.registerRpcEndpoint(Dispatcher.scala:65)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.rpc.netty.NettyRpcEnv.setupEndpoint(NettyRpcEnv.scala:136)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.scheduler.local.LocalBackend.start(LocalBackend.scala:126)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext.<init>(SparkContext.scala:530)[0m[0m
[0m[[0minfo[0m] [0m[31m  at data.LoadClaimDataSpec.beforeAll(LoadClaimDataSpec.scala:19)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)[0m[0m
[0m[[0minfo[0m] [0m[31m  at data.LoadClaimDataSpec.beforeAll(LoadClaimDataSpec.scala:9)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)[0m[0m
[0m[[0minfo[0m] [0m[31m  at data.LoadClaimDataSpec.run(LoadClaimDataSpec.scala:9)[0m[0m
[0m[[0minfo[0m] [0m[31m  ...[0m[0m
